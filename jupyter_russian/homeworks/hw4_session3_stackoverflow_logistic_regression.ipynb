{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "<center> Автор материала: Павел Нестеров (@mephistopheies).\n",
    "\n",
    "Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.5.2\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.1\n",
      "sklearn 0.19.0\n",
      "\n",
      "compiler   : GCC 5.4.0 20160609\n",
      "system     : Linux\n",
      "release    : 4.9.60-linuxkit-aufs\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n",
      "Git hash   : a372dc0d89664a1ddf5cff1488ec23c09a12d840\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = '../../data/stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = '../../data/top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android', 'php', 'jquery', 'c++', 'javascript', 'c#', 'html', 'ios', 'java', 'python'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'android': defaultdict(<class 'int'>, {}), 'jquery': defaultdict(<class 'int'>, {}), 'html': defaultdict(<class 'int'>, {}), 'php': defaultdict(<class 'int'>, {}), 'c++': defaultdict(<class 'int'>, {}), 'java': defaultdict(<class 'int'>, {}), 'javascript': defaultdict(<class 'int'>, {}), 'ios': defaultdict(<class 'int'>, {}), 'c#': defaultdict(<class 'int'>, {}), 'python': defaultdict(<class 'int'>, {})}\n"
     ]
    }
   ],
   "source": [
    "#Understanding the class initialization\n",
    "w = dict([(t, defaultdict(int)) for t in top_tags])\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_table(DS_FILE_NAME, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i ve got some code in window scroll that check...</td>\n",
       "      <td>javascript jquery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have a custom adapter for a list view it has...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in my form panel i added a checkbox setting st...</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i have the two dates variables startwork and e...</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i might have been using the wrong search tags ...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0                  1\n",
       "0  i ve got some code in window scroll that check...  javascript jquery\n",
       "1  i have a custom adapter for a list view it has...            android\n",
       "2  in my form panel i added a checkbox setting st...         javascript\n",
       "3  i have the two dates variables startwork and e...                 c#\n",
       "4  i might have been using the wrong search tags ...            android"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} = \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\textbf{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\textbf{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\textbf{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\textbf{x}\\right) &=& \\dfrac{p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\textbf{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} = \\sigma_k\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\textbf{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\textbf{x}, y}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\textbf{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\textbf{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\textbf{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\textbf{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\textbf{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. <font color=\"green\"> $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$ </font>\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font> В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. <font color = 'green'> $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$ </font>\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = 0\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "                        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "                        \n",
    "                        z+= self._b[tag] + self._w[tag][self._vocab[word]]*self._vocab[word]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    if z > 20:\n",
    "                        sigma = 1 / (1 + np.exp(-1*20))\n",
    "                    elif z < -20:\n",
    "                        sigma = 1 / (1 + np.exp(-1*(-20)))\n",
    "                    else:\n",
    "                        sigma = 1 / (1 + np.exp(-1*z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += - y*np.log(sigma) - (1 - y)*np.log(1 - sigma)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = self._vocab[word]*(y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa3a604315441b79e059867174b59bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7ac6da4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 14.70\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. <font color = 'green'> 17.54 </font>\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        probabilities = list()\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # z = ...\n",
    "                    z = 0\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        # z += ...\n",
    "                        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "                        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "                        \n",
    "                        z+= self._b[tag] + self._w[tag][self._vocab[word]]*self._vocab[word]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sigma = ...\n",
    "                    def sigma_calculation(z):\n",
    "                        if z > 20:\n",
    "                            return 1 / (1 + np.exp(-1*20))\n",
    "                        elif z < -20:\n",
    "                            return 1 / (1 + np.exp(-1*(-20)))\n",
    "                        else:\n",
    "                            return 1 / (1 + np.exp(-1*z))\n",
    "                    sigma = sigma_calculation(z)\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    # sample_loss += ...\n",
    "                    sample_loss += - y*np.log(sigma) - (1 - y)*np.log(1 - sigma)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    \n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        # dLdw = ...\n",
    "                        dLdw = self._vocab[word]*(y - sigma)\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    elif n > top_n_train:\n",
    "                            z = 0\n",
    "                            for word in sentence:\n",
    "                                if n >= top_n_train and word not in self._vocab:\n",
    "                                    continue\n",
    "                                if word not in self._vocab:\n",
    "                                    self._vocab[word] = len(self._vocab)\n",
    "                                z+=self._b[tag] + self._w[tag][self._vocab[word]]*self._vocab[word]\n",
    "                            probabilities.append(sigma_calculation(z))\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "        return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d485c337e426426292713afa8262c57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "a = model.iterate_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_f():\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5339637a7fd471abbc61ee61ec88871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "a float is required",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-04f1f393ea08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# выведем полученное значение с точностью до двух знаков\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%0.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: a float is required"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(\\textbf W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(\\textbf W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. <font color = 'green'> $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$ </font>\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(\\textbf W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
